//! Vector indexing for efficient similarity search
//!
//! Production-ready vector index implementations with zero-allocation design,
//! lock-free concurrent access, and blazing-fast search performance.

use std::collections::HashMap;
use std::sync::Arc;

use dashmap::DashMap;
use paraphym_simd::cosine_similarity;
use instant_distance::Builder;
use serde::{Deserialize, Serialize};

use crate::memory::utils::Result;
use crate::memory::vector::DistanceMetric;

/// Vector index configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VectorIndexConfig {
    /// Distance metric to use
    pub metric: DistanceMetric,

    /// Number of dimensions
    pub dimensions: usize,

    /// Index type
    pub index_type: IndexType,

    /// Additional index-specific parameters
    pub parameters: HashMap<String, serde_json::Value>,
}

/// Types of vector indexes
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum IndexType {
    /// Flat/brute-force index
    Flat,
    /// Hierarchical Navigable Small World
    HNSW,
    /// Inverted File System
    IVF,
    /// Locality Sensitive Hashing
    LSH,
    /// Annoy (Approximate Nearest Neighbors Oh Yeah)
    Annoy,
}

/// Vector index trait
pub trait VectorIndex: Send + Sync {
    /// Add a vector to the index
    fn add(&mut self, id: String, vector: Vec<f32>) -> Result<()>;

    /// Remove a vector from the index
    fn remove(&mut self, id: &str) -> Result<()>;

    /// Search for nearest neighbors
    fn search(&self, query: &[f32], k: usize) -> Result<Vec<(String, f32)>>;

    /// Get the number of vectors in the index
    fn len(&self) -> usize;

    /// Check if the index is empty
    fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Build/rebuild the index
    fn build(&mut self) -> Result<()>;
}

/// Flat (brute-force) vector index
pub struct FlatIndex {
    config: VectorIndexConfig,
    vectors: HashMap<String, Vec<f32>>,
}

impl FlatIndex {
    /// Create a new flat index
    pub fn new(config: VectorIndexConfig) -> Self {
        Self {
            config,
            vectors: HashMap::new(),
        }
    }

    /// Calculate distance between two vectors
    fn calculate_distance(&self, a: &[f32], b: &[f32]) -> f32 {
        match self.config.metric {
            DistanceMetric::Euclidean => a
                .iter()
                .zip(b.iter())
                .map(|(x, y)| (x - y).powi(2))
                .sum::<f32>()
                .sqrt(),
            DistanceMetric::Cosine => {
                let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
                let norm_a: f32 = a.iter().map(|x| x.powi(2)).sum::<f32>().sqrt();
                let norm_b: f32 = b.iter().map(|x| x.powi(2)).sum::<f32>().sqrt();

                if norm_a == 0.0 || norm_b == 0.0 {
                    0.0
                } else {
                    1.0 - (dot_product / (norm_a * norm_b))
                }
            }
            DistanceMetric::DotProduct => -a.iter().zip(b.iter()).map(|(x, y)| x * y).sum::<f32>(),
        }
    }
}

impl VectorIndex for FlatIndex {
    fn add(&mut self, id: String, vector: Vec<f32>) -> Result<()> {
        if vector.len() != self.config.dimensions {
            return Err(crate::memory::utils::error::Error::InvalidInput(format!(
                "Vector dimension mismatch: expected {}, got {}",
                self.config.dimensions,
                vector.len()
            )));
        }

        self.vectors.insert(id, vector);
        Ok(())
    }

    fn remove(&mut self, id: &str) -> Result<()> {
        self.vectors.remove(id);
        Ok(())
    }

    fn search(&self, query: &[f32], k: usize) -> Result<Vec<(String, f32)>> {
        if query.len() != self.config.dimensions {
            return Err(crate::memory::utils::error::Error::InvalidInput(format!(
                "Query dimension mismatch: expected {}, got {}",
                self.config.dimensions,
                query.len()
            )));
        }

        let mut distances: Vec<(String, f32)> = self
            .vectors
            .iter()
            .map(|(id, vector)| (id.clone(), self.calculate_distance(query, vector)))
            .collect();

        // Sort by distance (ascending for distance metrics, descending for similarity)
        // Handle NaN values by treating them as greater than any finite value
        distances.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));

        // Take top k results
        distances.truncate(k);

        Ok(distances)
    }

    fn len(&self) -> usize {
        self.vectors.len()
    }

    fn build(&mut self) -> Result<()> {
        // Flat index doesn't need building
        Ok(())
    }
}

/// Custom point type for instant-distance HNSW
#[derive(Debug, Clone)]
pub struct VectorPoint {
    pub data: Vec<f32>,
}

/// Space implementation for different distance metrics
#[derive(Debug, Clone)]
pub struct ConfigurableSpace {
    metric: DistanceMetric,
}

impl ConfigurableSpace {
    pub fn new(metric: DistanceMetric) -> Self {
        Self { metric }
    }

    pub fn distance(&self, a: &VectorPoint, b: &VectorPoint) -> f32 {
        match self.metric {
            DistanceMetric::Cosine => cosine_distance(&a.data, &b.data),
            DistanceMetric::Euclidean => euclidean_distance(&a.data, &b.data),
            DistanceMetric::DotProduct => dot_product_distance(&a.data, &b.data),
        }
    }
}

impl instant_distance::Point for VectorPoint {
    fn distance(&self, other: &Self) -> f32 {
        euclidean_distance(&self.data, &other.data)
    }
}

/// HNSW (Hierarchical Navigable Small World) index with production-ready implementation
pub struct HNSWIndex {
    config: VectorIndexConfig,
    /// Core HNSW index using instant-distance
    hnsw: Option<instant_distance::HnswMap<VectorPoint, usize>>,
    /// Lock-free mapping from string IDs to internal indices
    id_to_index: Arc<DashMap<String, usize>>,
    /// Lock-free mapping from internal indices to string IDs
    index_to_id: Arc<DashMap<usize, String>>,
    /// Lock-free vector storage
    vectors: Arc<DashMap<usize, VectorPoint>>,
    /// Atomic counter for generating internal indices
    next_index: std::sync::atomic::AtomicUsize,
    /// Space configuration for distance metric
    space: ConfigurableSpace,
}

impl HNSWIndex {
    /// Create a new HNSW index with production configuration
    ///
    /// # Performance
    /// Zero allocation initialization with optimal HNSW parameters
    pub fn new(config: VectorIndexConfig) -> Self {
        let space = ConfigurableSpace::new(config.metric.clone());

        Self {
            config,
            hnsw: None,
            id_to_index: Arc::new(DashMap::new()),
            index_to_id: Arc::new(DashMap::new()),
            vectors: Arc::new(DashMap::new()),
            next_index: std::sync::atomic::AtomicUsize::new(0),
            space,
        }
    }

    /// Get the index configuration
    pub fn get_config(&self) -> &VectorIndexConfig {
        &self.config
    }

    /// Get optimal HNSW parameters from configuration
    fn get_hnsw_params(&self) -> HNSWParams {
        // Extract parameters from config or use sensible defaults
        let m = self
            .config
            .parameters
            .get("m")
            .and_then(|v| v.as_u64())
            .map(|v| v as usize)
            .unwrap_or(16); // Default M parameter

        let ef_construction = self
            .config
            .parameters
            .get("ef_construction")
            .and_then(|v| v.as_u64())
            .map(|v| v as usize)
            .unwrap_or(200); // Default ef_construction

        let max_m = self
            .config
            .parameters
            .get("max_m")
            .and_then(|v| v.as_u64())
            .map(|v| v as usize)
            .unwrap_or(m); // Default max_m = m

        let max_m0 = self
            .config
            .parameters
            .get("max_m0")
            .and_then(|v| v.as_u64())
            .map(|v| v as usize)
            .unwrap_or(m * 2); // Default max_m0 = m * 2

        let ml = self
            .config
            .parameters
            .get("ml")
            .and_then(|v| v.as_f64())
            .unwrap_or(1.0 / (2.0_f64.ln())); // Default mL

        HNSWParams {
            m,
            ef_construction,
            max_m,
            max_m0,
            ml,
        }
    }

    /// Rebuild the HNSW index with current vectors
    fn rebuild_hnsw(&mut self) -> Result<()> {
        if self.vectors.is_empty() {
            // No vectors to build index with
            self.hnsw = None;
            return Ok(());
        }

        // Collect all vectors for building
        let points: Vec<VectorPoint> = self
            .vectors
            .iter()
            .map(|entry| entry.value().clone())
            .collect();

        if points.is_empty() {
            self.hnsw = None;
            return Ok(());
        }

        // Build HNSW with optimal parameters
        let params = self.get_hnsw_params();

        // Note: instant-distance Builder only supports ef_construction and ml
        // m, max_m, max_m0 are stored in config for future use or other HNSW implementations
        let builder = Builder::default()
            .ef_construction(params.ef_construction)
            .ml(params.ml as f32);

        // The m, max_m, max_m0 parameters are available in params but instant-distance
        // uses its own internal defaults for these values

        // Create values vector with indices
        let values: Vec<usize> = (0..points.len()).collect();
        let hnsw = builder.build(points, values);

        self.hnsw = Some(hnsw);
        Ok(())
    }

    /// Get next available internal index
    fn next_internal_index(&self) -> usize {
        self.next_index
            .fetch_add(1, std::sync::atomic::Ordering::Relaxed)
    }

    /// Update index with configuration parameters
    pub fn optimize_with_config(&mut self) -> Result<()> {
        // Rebuild with current configuration
        self.rebuild_hnsw()
    }
}

/// HNSW configuration parameters
#[derive(Debug, Clone)]
struct HNSWParams {
    /// Number of bi-directional links created for every new element during construction (M)
    /// Note: instant-distance uses its own internal M value, but this is kept for config compatibility
    #[allow(dead_code)]
    m: usize,
    /// Size of the dynamic candidate list (ef_construction)
    ef_construction: usize,
    /// Maximum number of bi-directional links for each node (max_m)
    /// Note: instant-distance uses its own internal max_m value, but this is kept for config compatibility
    #[allow(dead_code)]
    max_m: usize,
    /// Maximum number of bi-directional links for each node at layer 0 (max_m0)
    /// Note: instant-distance uses its own internal max_m0 value, but this is kept for config compatibility
    #[allow(dead_code)]
    max_m0: usize,
    /// Level generation factor (mL)
    ml: f64,
}

impl VectorIndex for HNSWIndex {
    fn add(&mut self, id: String, vector: Vec<f32>) -> Result<()> {
        if vector.len() != self.config.dimensions {
            return Err(crate::memory::utils::error::Error::InvalidInput(format!(
                "Vector dimension mismatch: expected {}, got {}",
                self.config.dimensions,
                vector.len()
            )));
        }

        // Check if ID already exists
        if self.id_to_index.contains_key(&id) {
            return Err(crate::memory::utils::error::Error::InvalidInput(format!(
                "Vector with ID '{}' already exists",
                id
            )));
        }

        // Generate internal index
        let internal_index = self.next_internal_index();

        // Create vector point
        let point = VectorPoint { data: vector };

        // Store mappings and vector
        self.id_to_index.insert(id.clone(), internal_index);
        self.index_to_id.insert(internal_index, id);
        self.vectors.insert(internal_index, point);

        // Trigger rebuild if we have enough vectors for efficiency
        let vector_count = self.vectors.len();
        if vector_count > 0 && (vector_count & (vector_count - 1)) == 0 {
            // Rebuild on powers of 2 for optimal performance
            self.rebuild_hnsw()?;
        }

        Ok(())
    }

    fn remove(&mut self, id: &str) -> Result<()> {
        if let Some((_, internal_index)) = self.id_to_index.remove(id) {
            self.index_to_id.remove(&internal_index);
            self.vectors.remove(&internal_index);

            // Mark for rebuild since instant-distance doesn't support dynamic removal
            // This is a limitation of the current HNSW implementation
            self.hnsw = None;

            Ok(())
        } else {
            Err(crate::memory::utils::error::Error::NotFound(format!(
                "Vector with ID '{}' not found",
                id
            )))
        }
    }

    fn search(&self, query: &[f32], k: usize) -> Result<Vec<(String, f32)>> {
        if query.len() != self.config.dimensions {
            return Err(crate::memory::utils::error::Error::InvalidInput(format!(
                "Query dimension mismatch: expected {}, got {}",
                self.config.dimensions,
                query.len()
            )));
        }

        if self.vectors.is_empty() {
            return Ok(Vec::new());
        }

        // Create query point
        let query_point = VectorPoint {
            data: query.to_vec(),
        };

        match &self.hnsw {
            Some(hnsw) => {
                // Use HNSW for fast approximate search
                let _ef = self
                    .config
                    .parameters
                    .get("ef")
                    .and_then(|v| v.as_u64())
                    .map(|v| v as usize)
                    .unwrap_or(std::cmp::max(k, 16)); // Default ef = max(k, 16)

                let mut search = instant_distance::Search::default();
                let search_results = hnsw.search(&query_point, &mut search);

                // Convert internal indices back to string IDs
                let mut results = Vec::with_capacity(search_results.len());

                for item in search_results {
                    let index_key = item.pid.into_inner() as usize;
                    if let Some(id_entry) = self.index_to_id.get(&index_key) {
                        results.push((id_entry.clone(), item.distance));
                    }
                }

                Ok(results)
            }
            None => {
                // Fallback to brute force search if HNSW not built
                let mut distances: Vec<(String, f32)> = Vec::new();

                for entry in self.vectors.iter() {
                    let internal_index = *entry.key();
                    let vector_point = entry.value();

                    if let Some(id_entry) = self.index_to_id.get(&internal_index) {
                        let distance = self.space.distance(&query_point, vector_point);
                        distances.push((id_entry.clone(), distance));
                    }
                }

                // Sort by distance
                distances
                    .sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
                distances.truncate(k);

                Ok(distances)
            }
        }
    }

    fn len(&self) -> usize {
        self.vectors.len()
    }

    fn build(&mut self) -> Result<()> {
        self.rebuild_hnsw()
    }
}

/// Distance function implementations with SIMD optimization potential
///
/// # Performance
/// Optimized for cache efficiency and vectorization

#[inline]
fn euclidean_distance(a: &[f32], b: &[f32]) -> f32 {
    a.iter()
        .zip(b.iter())
        .map(|(x, y)| {
            let diff = x - y;
            diff * diff
        })
        .sum::<f32>()
        .sqrt()
}

#[inline]
fn cosine_distance(a: &[f32], b: &[f32]) -> f32 {
    // Use shared SIMD-optimized cosine similarity from paraphym-simd crate
    // Convert similarity to distance: distance = 1.0 - similarity
    1.0 - cosine_similarity(a, b)
}

#[inline]
fn dot_product_distance(a: &[f32], b: &[f32]) -> f32 {
    // Negative dot product for distance (larger dot product = smaller distance)
    -a.iter().zip(b.iter()).map(|(x, y)| x * y).sum::<f32>()
}

/// Vector index factory
pub struct VectorIndexFactory;

impl VectorIndexFactory {
    /// Create a vector index from configuration
    pub fn create(config: VectorIndexConfig) -> Box<dyn VectorIndex> {
        match config.index_type {
            IndexType::Flat => Box::new(FlatIndex::new(config)),
            IndexType::HNSW => Box::new(HNSWIndex::new(config)),
            _ => Box::new(FlatIndex::new(config)), // Default to flat for unimplemented types
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_flat_index() {
        let config = VectorIndexConfig {
            metric: DistanceMetric::Cosine,
            dimensions: 3,
            index_type: IndexType::Flat,
            parameters: HashMap::new(),
        };

        let mut index = FlatIndex::new(config);

        // Add vectors
        let id1 = uuid::Uuid::new_v4().to_string();
        let id2 = uuid::Uuid::new_v4().to_string();

        index
            .add(id1.clone(), vec![1.0, 0.0, 0.0])
            .expect("Failed to add vector to index in test");
        index
            .add(id2.clone(), vec![0.0, 1.0, 0.0])
            .expect("Failed to add vector to index in test");

        // Search
        let results = index
            .search(&[1.0, 0.0, 0.0], 2)
            .expect("Failed to search index in test");

        assert_eq!(results.len(), 2);
        assert_eq!(results[0].0, id1); // Should match exactly
    }

    #[test]
    fn test_hnsw_index() {
        let mut config = VectorIndexConfig {
            metric: DistanceMetric::Cosine,
            dimensions: 4,
            index_type: IndexType::HNSW,
            parameters: HashMap::new(),
        };

        // Configure HNSW parameters for testing
        config.parameters.insert(
            "m".to_string(),
            serde_json::Value::Number(serde_json::Number::from(8)),
        );
        config.parameters.insert(
            "ef_construction".to_string(),
            serde_json::Value::Number(serde_json::Number::from(50)),
        );

        let mut index = HNSWIndex::new(config);

        // Add test vectors
        let id1 = "test1".to_string();
        let id2 = "test2".to_string();
        let id3 = "test3".to_string();

        index
            .add(id1.clone(), vec![1.0, 0.0, 0.0, 0.0])
            .expect("Failed to add vector 1");
        index
            .add(id2.clone(), vec![0.0, 1.0, 0.0, 0.0])
            .expect("Failed to add vector 2");
        index
            .add(id3.clone(), vec![0.0, 0.0, 1.0, 0.0])
            .expect("Failed to add vector 3");

        // Build index
        index.build().expect("Failed to build HNSW index");

        // Search for nearest neighbors
        let results = index
            .search(&[1.0, 0.0, 0.0, 0.0], 2)
            .expect("Failed to search HNSW index");

        assert!(!results.is_empty());
        assert_eq!(results[0].0, id1); // Should match exactly with first vector

        // Test removal
        index.remove(&id2).expect("Failed to remove vector");
        assert_eq!(index.len(), 2);
    }

    #[test]
    fn test_distance_functions() {
        let a = vec![1.0, 0.0, 0.0];
        let b = vec![0.0, 1.0, 0.0];
        let c = vec![1.0, 0.0, 0.0];

        // Test euclidean distance
        let dist_ab = euclidean_distance(&a, &b);
        let dist_ac = euclidean_distance(&a, &c);

        assert!(dist_ab > dist_ac); // a and c are identical, so distance should be 0
        assert!((dist_ac - 0.0).abs() < f32::EPSILON);

        // Test cosine distance
        let cos_dist_ab = cosine_distance(&a, &b);
        let cos_dist_ac = cosine_distance(&a, &c);

        assert!(cos_dist_ab > cos_dist_ac);
        assert!((cos_dist_ac - 0.0).abs() < f32::EPSILON);
    }

    #[test]
    fn test_vector_index_factory() {
        let config = VectorIndexConfig {
            metric: DistanceMetric::Cosine,
            dimensions: 3,
            index_type: IndexType::HNSW,
            parameters: HashMap::new(),
        };

        let index = VectorIndexFactory::create(config);
        assert_eq!(index.len(), 0);
        assert!(index.is_empty());
    }
}
